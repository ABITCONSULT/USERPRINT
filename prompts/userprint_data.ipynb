{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a51b3616-cda8-423f-8ae2-d1b36f1f0d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Building consolidated dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<00:00, 615.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Saving to userprint_data.csv\n",
      "âœ… Done! Dataset columns:\n",
      "Index(['Id', 'model', 'condition', 'prompt', 'response'], dtype='object')\n",
      "\n",
      "Total records: 5777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIG ===\n",
    "RESULTS_FOLDER = \"./\"  # Folder containing *_results.json files\n",
    "OUTPUT_FILE = \"userprint_data.csv\"\n",
    "PERSONA_CHAT_CSV = \"personality.csv\"\n",
    "CLUSTER_SUMMARIES_JSON = \"cluster_persona_summaries.json\"\n",
    "\n",
    "# Load supporting data first\n",
    "persona_chat_df = pd.read_csv(PERSONA_CHAT_CSV)\n",
    "with open(CLUSTER_SUMMARIES_JSON) as f:\n",
    "    cluster_summaries = json.load(f)\n",
    "\n",
    "# === Prompt Builder ===\n",
    "def build_prompt(row_id, condition):\n",
    "    \"\"\"Build prompt based on condition and original data\"\"\"\n",
    "    try:\n",
    "        chat_content = persona_chat_df.loc[row_id, 'chat']\n",
    "    except KeyError:\n",
    "        chat_content = \"\"\n",
    "    \n",
    "    persona_content = cluster_summaries.get(str(row_id % 10), \"\") if condition in ['persona_only', 'persona_plus_chat'] else None\n",
    "    \n",
    "    if condition == 'persona_plus_chat':\n",
    "        return f\"Persona: {persona_content}\\n\\nConversation:\\n{chat_content}\"\n",
    "    elif condition == 'persona_only':\n",
    "        return f\"Persona: {persona_content}\"\n",
    "    elif condition == 'chat_only':\n",
    "        return f\"Conversation:\\n{chat_content}\"\n",
    "    else:\n",
    "        return \"No content provided\"\n",
    "\n",
    "# === Load and Process Results ===\n",
    "def load_and_process_results(results_folder):\n",
    "    all_data = []\n",
    "    new_id = 1  # Starting ID counter\n",
    "    \n",
    "    # Process each results file\n",
    "    for filename in tqdm(os.listdir(results_folder), desc=\"Processing files\"):\n",
    "        if filename.endswith(\"_results.json\"):\n",
    "            with open(os.path.join(results_folder, filename)) as f:\n",
    "                model_name = filename.replace(\"ollama_\", \"\").replace(\"_results.json\", \"\").replace(\"_results21.json\", \"\")\n",
    "                model_data = json.load(f)\n",
    "                \n",
    "                for entry in model_data:\n",
    "                    # Skip error entries\n",
    "                    if entry['response'] == \"ERROR\":\n",
    "                        continue\n",
    "                        \n",
    "                    # Add new entry with generated ID\n",
    "                    all_data.append({\n",
    "                        'Id': new_id,\n",
    "                        'model': model_name,\n",
    "                        'condition': entry['condition'],\n",
    "                        'prompt': build_prompt(entry['id'], entry['condition']),\n",
    "                        'response': entry['response']\n",
    "                    })\n",
    "                    new_id += 1\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# === Main Execution ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸ“Š Building consolidated dataset...\")\n",
    "    df = load_and_process_results(RESULTS_FOLDER)\n",
    "    \n",
    "    print(f\"ðŸ’¾ Saving to {OUTPUT_FILE}\")\n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "    \n",
    "    print(\"âœ… Done! Dataset columns:\")\n",
    "    print(df.columns)\n",
    "    print(f\"\\nTotal records: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483db50b-62cf-4973-a946-b473a13880a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-env)",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
