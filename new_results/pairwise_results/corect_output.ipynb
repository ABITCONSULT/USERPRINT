{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf9de392-d7db-4879-a12d-2c61462eac92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing qwen3-0.6b_vs_llama4-400b.csv...\n",
      "Successfully cleaned qwen3-0.6b_vs_llama4-400b.csv\n",
      "Processing qwen3-latest_vs_gemma3-27b.csv...\n",
      "Successfully cleaned qwen3-latest_vs_gemma3-27b.csv\n",
      "Processing qwen3-0.6b_vs_gemma3-27b.csv...\n",
      "Successfully cleaned qwen3-0.6b_vs_gemma3-27b.csv\n",
      "Processing gemma3-27b_vs_mistral-small3.1-latest.csv...\n",
      "Successfully cleaned gemma3-27b_vs_mistral-small3.1-latest.csv\n",
      "Processing qwen2.5-latest_vs_mistral-small3.1-latest.csv...\n",
      "Successfully cleaned qwen2.5-latest_vs_mistral-small3.1-latest.csv\n",
      "Processing qwen3-latest_vs_qwen2.5-latest.csv...\n",
      "Successfully cleaned qwen3-latest_vs_qwen2.5-latest.csv\n",
      "Processing qwen3-latest_vs_qwen3-0.6b.csv...\n",
      "Successfully cleaned qwen3-latest_vs_qwen3-0.6b.csv\n",
      "Processing gpt4_vs_qwen3-0.6b.csv...\n",
      "Successfully cleaned gpt4_vs_qwen3-0.6b.csv\n",
      "Processing deepseek-r1-70b-alt_vs_mistral-small3.1-latest.csv...\n",
      "Successfully cleaned deepseek-r1-70b-alt_vs_mistral-small3.1-latest.csv\n",
      "Processing deepseek-r1-70b-alt_vs_gemma3-27b.csv...\n",
      "Successfully cleaned deepseek-r1-70b-alt_vs_gemma3-27b.csv\n",
      "Processing gpt4_vs_qwen3-latest.csv...\n",
      "Successfully cleaned gpt4_vs_qwen3-latest.csv\n",
      "Processing gpt4_vs_gemma3-27b.csv...\n",
      "Successfully cleaned gpt4_vs_gemma3-27b.csv\n",
      "Processing qwen3-latest_vs_deepseek-r1-70b-alt.csv...\n",
      "Successfully cleaned qwen3-latest_vs_deepseek-r1-70b-alt.csv\n",
      "Processing qwen3-latest_vs_mistral-small3.1-latest.csv...\n",
      "Successfully cleaned qwen3-latest_vs_mistral-small3.1-latest.csv\n",
      "Processing qwen2.5-latest_vs_gemma3-27b.csv...\n",
      "Successfully cleaned qwen2.5-latest_vs_gemma3-27b.csv\n",
      "Processing qwen3-latest_vs_llama4-400b.csv...\n",
      "Successfully cleaned qwen3-latest_vs_llama4-400b.csv\n",
      "Processing gpt4_vs_deepseek-r1-70b-alt.csv...\n",
      "Successfully cleaned gpt4_vs_deepseek-r1-70b-alt.csv\n",
      "Processing gpt4_vs_mistral-small3.1-latest.csv...\n",
      "Successfully cleaned gpt4_vs_mistral-small3.1-latest.csv\n",
      "Processing gpt4_vs_qwen2.5-latest.csv...\n",
      "Successfully cleaned gpt4_vs_qwen2.5-latest.csv\n",
      "Processing model_comparison_summary.csv...\n",
      "No 'verdict' column in model_comparison_summary.csv\n",
      "Processing qwen3-0.6b_vs_qwen2.5-latest.csv...\n",
      "Successfully cleaned qwen3-0.6b_vs_qwen2.5-latest.csv\n",
      "Processing gpt4_vs_llama4-400b.csv...\n",
      "Successfully cleaned gpt4_vs_llama4-400b.csv\n",
      "Processing deepseek-r1-70b-alt_vs_llama4-400b.csv...\n",
      "Successfully cleaned deepseek-r1-70b-alt_vs_llama4-400b.csv\n",
      "Processing qwen3-0.6b_vs_deepseek-r1-70b-alt.csv...\n",
      "Successfully cleaned qwen3-0.6b_vs_deepseek-r1-70b-alt.csv\n",
      "Processing llama4-400b_vs_gemma3-27b.csv...\n",
      "Successfully cleaned llama4-400b_vs_gemma3-27b.csv\n",
      "Processing qwen3-0.6b_vs_mistral-small3.1-latest.csv...\n",
      "Successfully cleaned qwen3-0.6b_vs_mistral-small3.1-latest.csv\n",
      "Processing llama4-400b_vs_mistral-small3.1-latest.csv...\n",
      "Successfully cleaned llama4-400b_vs_mistral-small3.1-latest.csv\n",
      "Processing deepseek-r1-70b-alt_vs_qwen2.5-latest.csv...\n",
      "Successfully cleaned deepseek-r1-70b-alt_vs_qwen2.5-latest.csv\n",
      "Processing llama4-400b_vs_qwen2.5-latest.csv...\n",
      "Successfully cleaned llama4-400b_vs_qwen2.5-latest.csv\n",
      "All files processed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_verdict(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    \n",
    "    # Pattern to match A, B, or Tie in various formats\n",
    "    pattern = r'[\"\\']?([AB]|Tie)[\"\\']?'\n",
    "    match = re.search(pattern, str(text))\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1)  # Return just A, B, or Tie\n",
    "    return text  # Return original if no match found\n",
    "\n",
    "# Process all CSV files in current directory\n",
    "for csv_file in Path('.').glob('*.csv'):\n",
    "    print(f\"Processing {csv_file.name}...\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        if 'verdict' in df.columns:\n",
    "            df['verdict'] = df['verdict'].apply(clean_verdict)\n",
    "            df.to_csv(csv_file, index=False)\n",
    "            print(f\"Successfully cleaned {csv_file.name}\")\n",
    "        else:\n",
    "            print(f\"No 'verdict' column in {csv_file.name}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {csv_file.name}: {str(e)}\")\n",
    "\n",
    "print(\"All files processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deda607a-b417-4a9b-b6c1-bc042b014ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing qwen3-0.6b_vs_llama4-400b.csv...\n",
      "✅ Cleaned: qwen3-0.6b_vs_llama4-400b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      379\n",
      "B      213\n",
      "Tie     20\n",
      "Name: count, dtype: int64\n",
      "Processing qwen3-latest_vs_gemma3-27b.csv...\n",
      "✅ Cleaned: qwen3-latest_vs_gemma3-27b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      357\n",
      "B      223\n",
      "Tie     32\n",
      "Name: count, dtype: int64\n",
      "Processing qwen3-0.6b_vs_gemma3-27b.csv...\n",
      "✅ Cleaned: qwen3-0.6b_vs_gemma3-27b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "B      320\n",
      "A      279\n",
      "Tie     13\n",
      "Name: count, dtype: int64\n",
      "Processing gemma3-27b_vs_mistral-small3.1-latest.csv...\n",
      "✅ Cleaned: gemma3-27b_vs_mistral-small3.1-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      380\n",
      "B      210\n",
      "Tie     22\n",
      "Name: count, dtype: int64\n",
      "Processing qwen2.5-latest_vs_mistral-small3.1-latest.csv...\n",
      "✅ Cleaned: qwen2.5-latest_vs_mistral-small3.1-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      390\n",
      "B      206\n",
      "Tie     16\n",
      "Name: count, dtype: int64\n",
      "Processing qwen3-latest_vs_qwen2.5-latest.csv...\n",
      "✅ Cleaned: qwen3-latest_vs_qwen2.5-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      414\n",
      "B      189\n",
      "Tie      9\n",
      "Name: count, dtype: int64\n",
      "Processing qwen3-latest_vs_qwen3-0.6b.csv...\n",
      "✅ Cleaned: qwen3-latest_vs_qwen3-0.6b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      432\n",
      "B      164\n",
      "Tie     16\n",
      "Name: count, dtype: int64\n",
      "Processing gpt4_vs_qwen3-0.6b.csv...\n",
      "✅ Cleaned: gpt4_vs_qwen3-0.6b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      443\n",
      "B      158\n",
      "Tie      8\n",
      "Name: count, dtype: int64\n",
      "Processing deepseek-r1-70b-alt_vs_mistral-small3.1-latest.csv...\n",
      "✅ Cleaned: deepseek-r1-70b-alt_vs_mistral-small3.1-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      410\n",
      "B      186\n",
      "Tie     16\n",
      "Name: count, dtype: int64\n",
      "Processing deepseek-r1-70b-alt_vs_gemma3-27b.csv...\n",
      "✅ Cleaned: deepseek-r1-70b-alt_vs_gemma3-27b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      336\n",
      "B      246\n",
      "Tie     30\n",
      "Name: count, dtype: int64\n",
      "Processing gpt4_vs_qwen3-latest.csv...\n",
      "✅ Cleaned: gpt4_vs_qwen3-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      385\n",
      "B      204\n",
      "Tie     20\n",
      "Name: count, dtype: int64\n",
      "Processing gpt4_vs_gemma3-27b.csv...\n",
      "✅ Cleaned: gpt4_vs_gemma3-27b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      324\n",
      "B      269\n",
      "Tie     16\n",
      "Name: count, dtype: int64\n",
      "Processing qwen3-latest_vs_deepseek-r1-70b-alt.csv...\n",
      "✅ Cleaned: qwen3-latest_vs_deepseek-r1-70b-alt.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      378\n",
      "B      199\n",
      "Tie     35\n",
      "Name: count, dtype: int64\n",
      "Processing qwen3-latest_vs_mistral-small3.1-latest.csv...\n",
      "✅ Cleaned: qwen3-latest_vs_mistral-small3.1-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      429\n",
      "B      165\n",
      "Tie     18\n",
      "Name: count, dtype: int64\n",
      "Processing qwen2.5-latest_vs_gemma3-27b.csv...\n",
      "✅ Cleaned: qwen2.5-latest_vs_gemma3-27b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      339\n",
      "B      251\n",
      "Tie     22\n",
      "Name: count, dtype: int64\n",
      "Processing qwen3-latest_vs_llama4-400b.csv...\n",
      "✅ Cleaned: qwen3-latest_vs_llama4-400b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      446\n",
      "B      154\n",
      "Tie     12\n",
      "Name: count, dtype: int64\n",
      "Processing gpt4_vs_deepseek-r1-70b-alt.csv...\n",
      "✅ Cleaned: gpt4_vs_deepseek-r1-70b-alt.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      363\n",
      "B      233\n",
      "Tie     13\n",
      "Name: count, dtype: int64\n",
      "Processing gpt4_vs_mistral-small3.1-latest.csv...\n",
      "✅ Cleaned: gpt4_vs_mistral-small3.1-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      350\n",
      "B      245\n",
      "Tie     14\n",
      "Name: count, dtype: int64\n",
      "Processing gpt4_vs_qwen2.5-latest.csv...\n",
      "✅ Cleaned: gpt4_vs_qwen2.5-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      358\n",
      "B      243\n",
      "Tie      8\n",
      "Name: count, dtype: int64\n",
      "Processing model_comparison_summary.csv...\n",
      "⚠️ No 'verdict' column in model_comparison_summary.csv\n",
      "Processing qwen3-0.6b_vs_qwen2.5-latest.csv...\n",
      "✅ Cleaned: qwen3-0.6b_vs_qwen2.5-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      336\n",
      "B      267\n",
      "Tie      9\n",
      "Name: count, dtype: int64\n",
      "Processing gpt4_vs_llama4-400b.csv...\n",
      "✅ Cleaned: gpt4_vs_llama4-400b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      365\n",
      "B      233\n",
      "Tie     11\n",
      "Name: count, dtype: int64\n",
      "Processing deepseek-r1-70b-alt_vs_llama4-400b.csv...\n",
      "✅ Cleaned: deepseek-r1-70b-alt_vs_llama4-400b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      444\n",
      "B      159\n",
      "Tie      9\n",
      "Name: count, dtype: int64\n",
      "Processing qwen3-0.6b_vs_deepseek-r1-70b-alt.csv...\n",
      "✅ Cleaned: qwen3-0.6b_vs_deepseek-r1-70b-alt.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      337\n",
      "B      264\n",
      "Tie     11\n",
      "Name: count, dtype: int64\n",
      "Processing llama4-400b_vs_gemma3-27b.csv...\n",
      "✅ Cleaned: llama4-400b_vs_gemma3-27b.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      320\n",
      "B      280\n",
      "Tie     12\n",
      "Name: count, dtype: int64\n",
      "Processing qwen3-0.6b_vs_mistral-small3.1-latest.csv...\n",
      "✅ Cleaned: qwen3-0.6b_vs_mistral-small3.1-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      333\n",
      "B      260\n",
      "Tie     19\n",
      "Name: count, dtype: int64\n",
      "Processing llama4-400b_vs_mistral-small3.1-latest.csv...\n",
      "✅ Cleaned: llama4-400b_vs_mistral-small3.1-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      363\n",
      "B      239\n",
      "Tie     10\n",
      "Name: count, dtype: int64\n",
      "Processing deepseek-r1-70b-alt_vs_qwen2.5-latest.csv...\n",
      "✅ Cleaned: deepseek-r1-70b-alt_vs_qwen2.5-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      397\n",
      "B      200\n",
      "Tie     15\n",
      "Name: count, dtype: int64\n",
      "Processing llama4-400b_vs_qwen2.5-latest.csv...\n",
      "✅ Cleaned: llama4-400b_vs_qwen2.5-latest.csv\n",
      "Sample verdicts after cleaning:\n",
      "verdict\n",
      "A      331\n",
      "B      270\n",
      "Tie     11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "All files processed! 🎉\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_verdict(text):\n",
    "    if pd.isna(text) or str(text).strip() == \"\":\n",
    "        return \"unknown\"\n",
    "    \n",
    "    text = str(text).strip()\n",
    "    \n",
    "    # Case-insensitive matching for A, B, or Tie (with optional quotes)\n",
    "    pattern = r'[\"\\']?(A|B|Tie)[\"\\']?'\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        verdict = match.group(1).capitalize()  # Ensure proper capitalization\n",
    "        if verdict.lower() == \"tie\":\n",
    "            return \"Tie\"\n",
    "        return verdict.upper()  # Return A or B in uppercase\n",
    "    return \"unknown\"\n",
    "\n",
    "# Process all CSV files\n",
    "for csv_file in Path('.').glob('*.csv'):\n",
    "    print(f\"Processing {csv_file.name}...\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        if 'verdict' in df.columns:\n",
    "            df['verdict'] = df['verdict'].apply(clean_verdict)\n",
    "            df.to_csv(csv_file, index=False)\n",
    "            print(f\"✅ Cleaned: {csv_file.name}\")\n",
    "            print(\"Sample verdicts after cleaning:\")\n",
    "            print(df['verdict'].value_counts())\n",
    "        else:\n",
    "            print(f\"⚠️ No 'verdict' column in {csv_file.name}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {csv_file.name}: {str(e)}\")\n",
    "\n",
    "print(\"\\nAll files processed! 🎉\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b27b7b95-834a-425e-b993-b8fd6e4a57db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing qwen3-0.6b_vs_llama4-400b.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen3-0.6b_vs_llama4-400b.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing qwen3-latest_vs_gemma3-27b.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen3-latest_vs_gemma3-27b.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing qwen3-0.6b_vs_gemma3-27b.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen3-0.6b_vs_gemma3-27b.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing gemma3-27b_vs_mistral-small3.1-latest.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved gemma3-27b_vs_mistral-small3.1-latest.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing qwen2.5-latest_vs_mistral-small3.1-latest.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen2.5-latest_vs_mistral-small3.1-latest.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing qwen3-latest_vs_qwen2.5-latest.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen3-latest_vs_qwen2.5-latest.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing qwen3-latest_vs_qwen3-0.6b.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen3-latest_vs_qwen3-0.6b.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing gpt4_vs_qwen3-0.6b.csv...\n",
      "Original rows: 609\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved gpt4_vs_qwen3-0.6b.csv\n",
      "Final row count: 609\n",
      "\n",
      "Processing deepseek-r1-70b-alt_vs_mistral-small3.1-latest.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved deepseek-r1-70b-alt_vs_mistral-small3.1-latest.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing deepseek-r1-70b-alt_vs_gemma3-27b.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved deepseek-r1-70b-alt_vs_gemma3-27b.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing gpt4_vs_qwen3-latest.csv...\n",
      "Original rows: 609\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved gpt4_vs_qwen3-latest.csv\n",
      "Final row count: 609\n",
      "\n",
      "Processing gpt4_vs_gemma3-27b.csv...\n",
      "Original rows: 609\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved gpt4_vs_gemma3-27b.csv\n",
      "Final row count: 609\n",
      "\n",
      "Processing qwen3-latest_vs_deepseek-r1-70b-alt.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen3-latest_vs_deepseek-r1-70b-alt.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing qwen3-latest_vs_mistral-small3.1-latest.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen3-latest_vs_mistral-small3.1-latest.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing qwen2.5-latest_vs_gemma3-27b.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen2.5-latest_vs_gemma3-27b.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing qwen3-latest_vs_llama4-400b.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen3-latest_vs_llama4-400b.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing gpt4_vs_deepseek-r1-70b-alt.csv...\n",
      "Original rows: 609\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved gpt4_vs_deepseek-r1-70b-alt.csv\n",
      "Final row count: 609\n",
      "\n",
      "Processing gpt4_vs_mistral-small3.1-latest.csv...\n",
      "Original rows: 609\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved gpt4_vs_mistral-small3.1-latest.csv\n",
      "Final row count: 609\n",
      "\n",
      "Processing gpt4_vs_qwen2.5-latest.csv...\n",
      "Original rows: 609\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved gpt4_vs_qwen2.5-latest.csv\n",
      "Final row count: 609\n",
      "\n",
      "Processing model_comparison_summary.csv...\n",
      "Original rows: 7\n",
      "No 'verdict' column found\n",
      "Successfully processed and saved model_comparison_summary.csv\n",
      "Final row count: 7\n",
      "\n",
      "Processing qwen3-0.6b_vs_qwen2.5-latest.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen3-0.6b_vs_qwen2.5-latest.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing gpt4_vs_llama4-400b.csv...\n",
      "Original rows: 609\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved gpt4_vs_llama4-400b.csv\n",
      "Final row count: 609\n",
      "\n",
      "Processing deepseek-r1-70b-alt_vs_llama4-400b.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved deepseek-r1-70b-alt_vs_llama4-400b.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing qwen3-0.6b_vs_deepseek-r1-70b-alt.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen3-0.6b_vs_deepseek-r1-70b-alt.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing llama4-400b_vs_gemma3-27b.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved llama4-400b_vs_gemma3-27b.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing qwen3-0.6b_vs_mistral-small3.1-latest.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved qwen3-0.6b_vs_mistral-small3.1-latest.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing llama4-400b_vs_mistral-small3.1-latest.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved llama4-400b_vs_mistral-small3.1-latest.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing deepseek-r1-70b-alt_vs_qwen2.5-latest.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved deepseek-r1-70b-alt_vs_qwen2.5-latest.csv\n",
      "Final row count: 612\n",
      "\n",
      "Processing llama4-400b_vs_qwen2.5-latest.csv...\n",
      "Original rows: 612\n",
      "Verdict column cleaned\n",
      "Successfully processed and saved llama4-400b_vs_qwen2.5-latest.csv\n",
      "Final row count: 612\n",
      "\n",
      "All files processed! 🎉\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_verdict(text):\n",
    "    if pd.isna(text):\n",
    "        return \"unknown\"\n",
    "    \n",
    "    text = str(text).strip()\n",
    "    pattern = r'[\"\\']?(A|B|Tie)[\"\\']?'\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        verdict = match.group(1).capitalize()\n",
    "        return \"Tie\" if verdict.lower() == \"tie\" else verdict.upper()\n",
    "    return \"unknown\"\n",
    "\n",
    "# Process all CSV files in current directory\n",
    "for csv_file in Path('.').glob('*.csv'):\n",
    "    print(f\"\\nProcessing {csv_file.name}...\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        original_rows = len(df)\n",
    "        print(f\"Original rows: {original_rows}\")\n",
    "        \n",
    "        # Delete first 288 rows if file has 900+ rows\n",
    "        if original_rows >= 900:\n",
    "            df = df.iloc[288:]\n",
    "            print(f\"Removed first 288 rows. New row count: {len(df)}\")\n",
    "        \n",
    "        # Clean verdict column if exists\n",
    "        if 'verdict' in df.columns:\n",
    "            df['verdict'] = df['verdict'].apply(clean_verdict)\n",
    "            print(\"Verdict column cleaned\")\n",
    "        else:\n",
    "            print(\"No 'verdict' column found\")\n",
    "        \n",
    "        # Save processed file\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"Successfully processed and saved {csv_file.name}\")\n",
    "        print(f\"Final row count: {len(df)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {csv_file.name}: {str(e)}\")\n",
    "\n",
    "print(\"\\nAll files processed! 🎉\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f048db5-680c-469b-afe1-bec3de406f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-env)",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
